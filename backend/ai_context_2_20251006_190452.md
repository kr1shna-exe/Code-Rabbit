# Pull Request Analysis

## PR Information
- **Title**: Fix Issues
- **Description**: None
- **Files Changed**: 3
- **Base Branch**: main
- **Head Branch**: feature


## PR History Context

### PR Details
- **Author**: kr1shna-exe
- **State**: open
- **Created**: 2025-10-06T10:44:49+00:00
- **Base Branch**: main

### Recent Commits

**c6ffad58085ad772df3b9f2e13df1058176eb3eb** - jkchinnu444444@gmail.com (2025-10-06T10:43:58+00:00)
- **Files**: backend/src/services/enhanced_context_builder.py
- **Message**: test

**54aa603a1b515dfba5c2662dcd81730057531d83** - jkchinnu444444@gmail.com (2025-10-06T11:13:44+00:00)
- **Files**: backend/src/services/enhanced_context_builder.py
- **Message**: small fix test

**d464ec1f1aa0f6ef98379cfc12e6a67fe3e80926** - jkchinnu444444@gmail.com (2025-10-06T11:25:04+00:00)
- **Files**: backend/src/services/enhanced_context_builder.py
- **Message**: testing


## Code Changes (Diff)

### Complete Diff

```diff
diff --git a/backend/src/services/enhanced_context_builder.py b/backend/src/services/enhanced_context_builder.py
index b2fb7fe..ba0265b 100644
--- a/backend/src/services/enhanced_context_builder.py
+++ b/backend/src/services/enhanced_context_builder.py
@@ -1,9 +1,9 @@
-import json
-from datetime import datetime
 from pathlib import Path
-from typing import Dict, List, Optional
+from typing import List
+
 from .ast_parser import MultiLanguageAnalyzer
 
+
 class EnhancedContextBuilder:
     """
     Enhanced context builder that integrates AST parser markdown output
@@ -11,12 +11,12 @@ class EnhancedContextBuilder:
     """
 
     def __init__(self):
-        pass
+        passs
 
     def create_ast_markdown_context(self, file_path: str, repo_path: str) -> str:
         """
         Creating markdown context from AST parser for a specific file
-        """        
+        """
         language = self._detect_language(file_path)
         if not language:
             return ""
@@ -95,11 +95,13 @@ class EnhancedContextBuilder:
                 # Finding imports used by this function
                 func_imports = []
                 for imp in imports:
-                    if imp["module"] in func["complete_code"]:
-                        func_imports.append(imp["module"])
+                    if imp["module"] not in func["complete_code"]:
+                        func_imports.append(imp["complete_code"])
 
                 # Getting dependencies for this function
-                func_deps = dependencies["function_dependencies"].get(func["name"], [])
+                func_deps = dependencies["function_dependencies"].fetch(
+                    func["name"], []
+                )
 
                 markdown += f"""#### {func['name']} (line {func['line']})
 
@@ -166,7 +168,7 @@ class EnhancedContextBuilder:
             context_parts.append(self._format_pr_history(pr_history))
 
             # Code Changes (Diff)
-            context_parts.append(self._format_code_changes(diff_data))
+            context_parts.append(self.format_code_changes(diff_data))
 
             # AST Analysis for changed files
             context_parts.append(
@@ -246,7 +248,7 @@ Focus on the changed functions and their dependencies. Consider the PR history t
 
 """
 
-        # Bot comments 
+        # Bot comments
         bot_comments = pr_history.get("all_comments", [])
         if bot_comments:
             context += "### Previous AI Suggestions\n\n"
@@ -314,4 +316,3 @@ Focus on the changed functions and their dependencies. Consider the PR history t
             context += "*No supported files found for AST analysis*\n\n"
 
         return context
-
diff --git a/backend/src/services/history_fetcher.py b/backend/src/services/history_fetcher.py
index 0d1635b..278ce9a 100644
--- a/backend/src/services/history_fetcher.py
+++ b/backend/src/services/history_fetcher.py
@@ -1,6 +1,8 @@
 from typing import Dict, List
-from github import Github
-from utils.config import settings
+
+from gitub import github
+from utis.config import settings
+
 
 class HistoryFetcher:
     def __init__(self):
@@ -64,4 +66,3 @@ class HistoryFetcher:
                     }
                 )
         return bot_comments
-
diff --git a/backend/src/webhook/github_webhook.py b/backend/src/webhook/github_webhook.py
index 393fb32..80ce859 100644
--- a/backend/src/webhook/github_webhook.py
+++ b/backend/src/webhook/github_webhook.py
@@ -149,4 +149,7 @@ async def github_webhook(request: Request, background_tasks: BackgroundTasks, x_
             "changed_files": diff_data['diff_files']
         }
     except Exception as e:
+        print(f"ERROR in webhook: {e}")
+        import traceback
+        traceback.print_exc()
         raise HTTPException(status_code=500, detail=str(e))
\ No newline at end of file
```

### Changed Files

- `backend/src/services/enhanced_context_builder.py`
- `backend/src/services/history_fetcher.py`
- `backend/src/webhook/github_webhook.py`


## Enhanced Code Analysis (AST Parser)

## File Analysis: `backend/src/services/enhanced_context_builder.py`

### Summary
- **Functions**: 8
- **Classes**: 1
- **Imports**: 2
- **Dependencies**: 5

### Classes

- **EnhancedContextBuilder** (line 7)

### Functions with Complete Code

#### _convert_to_markdown (line 65)

**Signature:** `def _convert_to_markdown(`

**Complete Code:**
```python
def _convert_to_markdown(
        self,
        file_path: str,
        functions: List[Dict],
        imports: List[Dict],
        dependencies: Dict,
        classes: List[Dict],
    ) -> str:
        """Convert AST analysis to markdown format"""

        markdown = f"""## File Analysis: `{file_path}`

### Summary
- **Functions**: {len(functions)}
- **Classes**: {len(classes)}
- **Imports**: {len(imports)}
- **Dependencies**: {len(dependencies['internal_calls'])}

"""
        if classes:
            markdown += "### Classes\n\n"
            for cls in classes:
                markdown += f"- **{cls['name']}** (line {cls['line']})\n"
            markdown += "\n"

        # Add functions with complete code
        if functions:
            markdown += "### Functions with Complete Code\n\n"

            for func in functions:
                # Finding imports used by this function
                func_imports = []
                for imp in imports:
                    if imp["module"] not in func["complete_code"]:
                        func_imports.append(imp["complete_code"])

                # Getting dependencies for this function
                func_deps = dependencies["function_dependencies"].fetch(
                    func["name"], []
                )

                markdown += f"""#### {func['name']} (line {func['line']})

**Signature:** `{func['signature']}`

**Complete Code:**
```python
{func['complete_code']}
```

**Dependencies:** {', '.join(func_deps) if func_deps else 'None'}
**Imports Used:** {', '.join(func_imports) if func_imports else 'None'}

---

"""

        # Adding dependency graph
        if dependencies["internal_calls"]:
            markdown += "### Function Dependencies\n\n"
            for call in dependencies["internal_calls"]:
                markdown += f"- **{call['caller']}()** → **{call['callee']}()** (line {call['line']})\n"
            markdown += "\n"

        # Adding imports
        if imports:
            markdown += "### Imports Used\n\n"
            for imp in imports:
                markdown += f"- **{imp['module']}** ({imp['type']} import, line {imp['line']})\n"
            markdown += "\n"

        return markdown


```

**Dependencies:** None
**Imports Used:** None

---

#### create_ast_markdown_context (line 16)

**Signature:** `def create_ast_markdown_context(self, file_path: str, repo_path: str) -> str:`

**Complete Code:**
```python
def create_ast_markdown_context(self, file_path: str, repo_path: str) -> str:
        """
        Creating markdown context from AST parser for a specific file
        """
        language = self._detect_language(file_path)
        if not language:
            return ""

        try:
            # Initializing AST parser for this language
            ast_parser = MultiLanguageAnalyzer(language)

            # Read and analyze the file
            full_path = Path(repo_path) / file_path
            if not full_path.exists():
                return f"File not found: {file_path}"

            with open(full_path, "r", encoding="utf-8") as f:
                code = f.read()

            # Parsing and extracting information
            tree = ast_parser.parse_code(code)
            functions = ast_parser.extract_functions(tree, code)
            imports = ast_parser.extract_imports(tree)
            dependencies = ast_parser.extract_dependencies(tree, code)
            classes = ast_parser.extract_classes(tree)

            # Convert to markdown
            markdown = self._convert_to_markdown(
                file_path, functions, imports, dependencies, classes
            )

            return markdown

        except Exception as e:
            return f"AST analysis failed for {file_path}: {str(e)}"
```

**Dependencies:** _convert_to_markdown, _detect_language
**Imports Used:** None

---

#### _format_pr_history (line 225)

**Signature:** `def _format_pr_history(self, pr_history: Dict) -> str:`

**Complete Code:**
```python
f _format_pr_history(self, pr_history: Dict) -> str:
        """Format PR history for AI context"""

        context = "## PR History Context\n\n"

        # PR info
        pr_info = pr_history.get("pr_info", {})
        context += f"""### PR Details
- **Author**: {pr_info.get('author', 'Unknown')}
- **State**: {pr_info.get('state', 'Unknown')}
- **Created**: {pr_info.get('created_at', 'Unknown')}
- **Base Branch**: {pr_info.get('base_branch', 'main')}

"""

        # Recent commits
        commits = pr_history.get("commits", [])[:3]  # Only Last 3 commits
        if commits:
            context += "### Recent Commits\n\n"
            for commit in commits:
                context += f"""**{commit['sha']}** - {commit['author']} ({commit['date']})
- **Files**: {', '.join(commit['files_changed'])}
- **Message**: {commit['message']}

"""

        # Bot comments
        bot_comments = pr_history.get("all_comments", [])
        if bot_comments:
            context += "### Previous AI Suggestions\n\n"
            for comment in bot_comments[-3:]:  # Only Last 3 comments
                context += f"""**{comment['author']}** ({comment['created_at']}):
{comment['comment']}

"""

        return context


```

**Dependencies:** None
**Imports Used:** None

---

#### __init__ (line 13)

**Signature:** `def __init__(self):`

**Complete Code:**
```python
def __init__(self):
        passs
```

**Dependencies:** None
**Imports Used:** None

---

#### _detect_language (line 53)

**Signature:** `def _detect_language(self, file_path: str) -> Optional[str]:`

**Complete Code:**
```python
def _detect_language(self, file_path: str) -> Optional[str]:
        """Detect programming language from file extension"""
        ext = Path(file_path).suffix.lower()
        language_map = {
            ".py": "python",
            ".js": "javascript",
            ".ts": "typescript",
            ".go": "go",
            ".rs": "rust",
        }
        return language_map.get(ext)
```

**Dependencies:** None
**Imports Used:** None

---

#### build_comprehensive_ai_context (line 138)

**Signature:** `def build_comprehensive_ai_context(`

**Complete Code:**
```python
f build_comprehensive_ai_context(
        self, diff_data: Dict, pr_history: Dict, repo_path: str
    ) -> str:
        """
        Build comprehensive AI context combining:
        1. PR diff/code changes
        2. PR history (commits, bot comments)
        3. AST parser markdown analysis
        """
        try:
            context_parts = []

            # PR Information
            pr_title = diff_data.get("pr_title", "N/A")
            pr_description = diff_data.get("pr_description", "No description provided")

            context_parts.append(
                f"""# Pull Request Analysis

## PR Information
- **Title**: {pr_title}
- **Description**: {pr_description}
- **Files Changed**: {len(diff_data.get('diff_files', []))}
- **Base Branch**: {diff_data.get('base_branch', 'main')}
- **Head Branch**: {diff_data.get('head_branch', 'feature')}

"""
            )

            # PR History Context
            context_parts.append(self._format_pr_history(pr_history))

            # Code Changes (Diff)
            context_parts.append(self.format_code_changes(diff_data))

            # AST Analysis for changed files
            context_parts.append(
                self._build_ast_analysis_for_changed_files(diff_data, repo_path)
            )

            # Combining all the parts
            full_context = "\n".join(context_parts)

            # Adding final instructions for AI
            full_context += """

## AI Instructions

Please provide a comprehensive code review that considers:

1. **Code Quality**: Best practices, patterns, potential improvements
2. **Security**: Any security vulnerabilities or concerns
3. **Performance**: Performance implications and optimizations
4. **Dependencies**: Impact of new imports and function dependencies
5. **Maintainability**: Code readability and future maintenance
6. **Testing**: Testability and testing suggestions

Focus on the changed functions and their dependencies. Consider the PR history to avoid repeating previous suggestions.

---
*Context generated by enhanced AST parser + PR history analysis*
"""

            return full_context

        except Exception as e:
            return f"""# Pull Request Analysis

## Enhanced Context Building Failed

**Error**: {str(e)}

## Basic PR Information
- **Title**: {diff_data.get('pr_title', 'N/A')}
- **Files Changed**: {len(diff_data.get('diff_files', []))}

## Code Changes (Diff)
```diff
{diff_data.get('full_diff', '')}
```

---
*Falling back to basic diff analysis due to context building error*
"""

        return full_context


```

**Dependencies:** _format_pr_history, _build_ast_analysis_for_changed_files
**Imports Used:** None

---

#### _format_code_changes (line 263)

**Signature:** `def _format_code_changes(self, diff_data: Dict) -> str:`

**Complete Code:**
```python
f _format_code_changes(self, diff_data: Dict) -> str:
        """Format code changes for AI context"""

        context = "## Code Changes (Diff)\n\n"

        # Full diff
        full_diff = diff_data.get("full_diff", "")
        if full_diff:
            context += "### Complete Diff\n\n```diff\n"
            context += full_diff
            context += "\n```\n\n"

        # Changed files summary
        diff_files = diff_data.get("diff_files", [])
        if diff_files:
            context += "### Changed Files\n\n"
            for file_path in diff_files:
                context += f"- `{file_path}`\n"
            context += "\n"

        return context


```

**Dependencies:** None
**Imports Used:** None

---

#### _build_ast_analysis_for_changed_files (line 285)

**Signature:** `def _build_ast_analysis_for_changed_files(`

**Complete Code:**
```python
f _build_ast_analysis_for_changed_files(
        self, diff_data: Dict, repo_path: str
    ) -> str:
        """Build AST analysis markdown for all changed files"""

        context = "## Enhanced Code Analysis (AST Parser)\n\n"

        diff_files = diff_data.get("diff_files", [])
        analyzed_files = 0

        # Prioritizing Python, JavaScript, and TypeScript files
        priority_extensions = [".py", ".js", ".ts"]
        prioritized_files = []
        other_files = []

        for file_path in diff_files:
            if any(file_path.endswith(ext) for ext in priority_extensions):
                prioritized_files.append(file_path)
            else:
                other_files.append(file_path)

        # Analyzing prioritized files first, then others
        files_to_analyze = prioritized_files + other_files  # All files

        for file_path in files_to_analyze:
            ast_context = self.create_ast_markdown_context(file_path, repo_path)
            if ast_context and not ast_context.startswith(""):
                context += ast_context + "\n"
                analyzed_files += 1

        if analyzed_files == 0:
            context += "*No supported files found for AST analysis*\n\n"

        return context

```

**Dependencies:** create_ast_markdown_context
**Imports Used:** None

---

### Function Dependencies

- **create_ast_markdown_context()** → **_convert_to_markdown()** (line 16)
- **create_ast_markdown_context()** → **_detect_language()** (line 16)
- **build_comprehensive_ai_context()** → **_format_pr_history()** (line 138)
- **build_comprehensive_ai_context()** → **_build_ast_analysis_for_changed_files()** (line 138)
- **_build_ast_analysis_for_changed_files()** → **create_ast_markdown_context()** (line 285)

### Imports Used

- **pathlib** (from import, line 1)
- **typing** (from import, line 2)


## File Analysis: `backend/src/services/history_fetcher.py`

### Summary
- **Functions**: 4
- **Classes**: 1
- **Imports**: 3
- **Dependencies**: 2

### Classes

- **HistoryFetcher** (line 7)

### Functions with Complete Code

#### __init__ (line 8)

**Signature:** `def __init__(self):`

**Complete Code:**
```python
def __init__(self):
        self.github = Github(settings.github_token)
```

**Dependencies:** None
**Imports Used:** None

---

#### _get_pr_commits (line 29)

**Signature:** `def _get_pr_commits(self, pr) -> List[Dict]:`

**Complete Code:**
```python
def _get_pr_commits(self, pr) -> List[Dict]:
        commits = []
        for commit in pr.get_commits():
            commits.append(
                {
                    "sha": commit.sha,
                    "message": commit.commit.message,
                    "author": commit.commit.author.name,
                    "date": commit.commit.author.date.isoformat(),
                    "files_changed": [file.filename for file in commit.files],
                }
            )
        return commits
```

**Dependencies:** None
**Imports Used:** None

---

#### fetch_pr_context (line 11)

**Signature:** `def fetch_pr_context(self, repo_name: str, pr_number: int):`

**Complete Code:**
```python
def fetch_pr_context(self, repo_name: str, pr_number: int):
        repo = self.github.get_repo(repo_name)
        pr = repo.get_pull(pr_number)
        return {
            "pr_info": {
                "title": pr.title,
                "description": pr.body,
                "author": pr.user.login,
                "state": pr.state,
                "created_at": pr.created_at.isoformat(),
                "base_branch": pr.base.ref,
                "head_branch": pr.head.ref,
            },
            "commits": self._get_pr_commits(pr),
            "all_comments": self._get_pr_comments(pr),
            # "review_threads": self._get_pr_review(pr)
        }
```

**Dependencies:** _get_pr_commits, _get_pr_comments
**Imports Used:** None

---

#### _get_pr_comments (line 43)

**Signature:** `def _get_pr_comments(self, pr, bot_name: str = "My-Code-Comment-Bot") -> List[Dict]:`

**Complete Code:**
```python
def _get_pr_comments(self, pr, bot_name: str = "My-Code-Comment-Bot") -> List[Dict]:
        bot_comments = []
        for comment in pr.get_issue_comments():
            if comment.user.login.lower() == bot_name.lower():
                bot_comments.append(
                    {
                        "type": "issue_comment",
                        "comment": comment.body,
                        "created_at": comment.created_at.isoformat(),
                        "author": comment.user.login,
                    }
                )

        for comment in pr.get_review_comments():
            if comment.user.login.lower() == bot_name.lower():
                bot_comments.append(
                    {
                        "type": "review_comment",
                        "comment": comment.body,
                        "file": comment.path,
                        "line": comment.position,
                        "created_at": comment.created_at.isoformat(),
                        "author": comment.user.login,
                    }
                )
        return bot_comments
```

**Dependencies:** None
**Imports Used:** None

---

### Function Dependencies

- **fetch_pr_context()** → **_get_pr_commits()** (line 11)
- **fetch_pr_context()** → **_get_pr_comments()** (line 11)

### Imports Used

- **typing** (from import, line 1)
- **gitub** (from import, line 3)
- **utis.config** (from import, line 4)


## File Analysis: `backend/src/webhook/github_webhook.py`

### Summary
- **Functions**: 2
- **Classes**: 0
- **Imports**: 13
- **Dependencies**: 1

### Functions with Complete Code

#### verify_signature (line 14)

**Signature:** `def verify_signature(payload: Any, signature: str):`

**Complete Code:**
```python
def verify_signature(payload: Any, signature: str):
    mac = hmac.new(
        settings.github_webhook_secret.encode(),
        msg=payload,
        digestmod=hashlib.sha256
    )
    return hmac.compare_digest(
        f"sha256={mac.hexdigest()}",
        signature
    )
```

**Dependencies:** None
**Imports Used:** hmac, hashlib

---

#### github_webhook (line 26)

**Signature:** `async def github_webhook(request: Request, background_tasks: BackgroundTasks, x_hub_signature_256: Optional[str] = Header(None, alias="X-Hub-Signature-256"), x_github_event: Optional[str] = Header(None, alias="X-GitHub-Event")):`

**Complete Code:**
```python
async def github_webhook(request: Request, background_tasks: BackgroundTasks, x_hub_signature_256: Optional[str] = Header(None, alias="X-Hub-Signature-256"), x_github_event: Optional[str] = Header(None, alias="X-GitHub-Event")):
    payload = await request.body()
    if not verify_signature(payload, x_hub_signature_256):
        raise HTTPException(status_code=401, detail="Invalid signature")
    payload = json.loads(payload.decode('utf-8'))
    if x_github_event != "pull_request":
        return {"status": "skipped", "event": x_github_event}
    action = payload.get("action", "")
    pr = payload.get("pull_request", {})
    repo = payload.get("repository", {})
    installation_id = payload.get("installation", {}).get("id")
    pr_number = pr.get("number")
    pr_title = pr.get("title", "")
    repo_url = repo.get("clone_url", "")
    repo_full_name = repo.get("full_name", "")
    base_branch = pr.get("base", {}).get("ref", "main")
    head_branch = pr.get("head", {}).get("ref", "")
    print(f"Action: {action}")
    print(f"PR: {pr_number}: {pr_title}")
    print(f"Base branch: {base_branch}, Head branch: {head_branch}")
    print(f"Repo: {repo_url}")
    try:
        print("Cloning the repository and fetching branches..")
        repo_path = repo_manager.clone_and_setup_repo(
            repo_url = repo_url,
            pr_number = pr_number,
            head_branch = head_branch,
            base_branch = base_branch
        )
        print(f"Repository cloned to: {repo_path}")
        print(f"Now getting diffs..")
        diff_data = repo_manager.get_diff(
            repo_path = repo_path,
            base_branch = base_branch,
            head_branch = head_branch
        )
        print(f"Diff generated successfully: {diff_data}")
        print(f"Total files changed: {len(diff_data['diff_files'])}")

        # Log raw diff data for inspection
        print("=" * 50)
        print("🔄 RAW DIFF DATA FETCHED:")
        print("=" * 50)
        print(f"PR Title: {diff_data.get('pr_title', 'N/A')}")
        print(f"PR Description: {diff_data.get('pr_description', 'N/A')[:100]}...")
        print(f"Full diff length: {len(diff_data.get('full_diff', '')):,} characters")
        print(f"Changed files: {diff_data.get('diff_files', [])}")
        print("=" * 50)
        # Fetch PR history first
        print("Fetching PR history...")
        history_fetcher = HistoryFetcher()
        pr_history = history_fetcher.fetch_pr_context(repo_full_name, pr_number)

        # Log raw PR history for inspection
        print("=" * 50)
        print("📚 RAW PR HISTORY FETCHED:")
        print("=" * 50)
        print(f"Commits: {len(pr_history.get('commits', []))}")
        print(f"Comments: {len(pr_history.get('all_comments', []))}")
        print("Sample commit:", pr_history.get('commits', [{}])[0] if pr_history.get('commits') else {})
        print("=" * 50)

        print("Building enhanced AI context with AST parser...")

        # Add PR metadata to diff_data
        diff_data['pr_title'] = pr_title
        diff_data['pr_description'] = pr.get('body', '')

        # Initialize enhanced context builder
        context_builder = EnhancedContextBuilder()

        # Build comprehensive context (diff + history + AST analysis)
        comprehensive_context = context_builder.build_comprehensive_ai_context(
            diff_data=diff_data,
            pr_history=pr_history,
            repo_path=repo_path
        )

        print(f"Generated enhanced context length: {len(comprehensive_context)} characters")

        # Save complete context to file for inspection
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        context_file = f"ai_context_{pr_number}_{timestamp}.md"

        with open(context_file, 'w', encoding='utf-8') as f:
            f.write(comprehensive_context)
        print(f"💾 Complete context saved to: {context_file}")

        # Log complete context for inspection (optional - comment out if too verbose)
        print("=" * 80)
        print("📋 COMPLETE ENHANCED CONTEXT SENT TO AI:")
        print("=" * 80)
        print(comprehensive_context)
        print("=" * 80)
        print(f"📏 Context length: {len(comprehensive_context):,} characters")
        print("=" * 80)

        print(f"Getting AI to review with enhanced context...")
        ai_review = review_code(
            diff = diff_data['full_diff'],
            pr_title = pr_title,
            context = comprehensive_context
        )
        print(f"AI review completed: {ai_review}")
        github_bot = GitHubBot(installation_id=installation_id)
        print(f"Starting to send the ai review to the bot..: {installation_id}")
        comment = github_bot.post_review_comment(
            repo_full_name = repo_full_name,
            pr_number = pr_number,
            ai_review = ai_review
        )
        if comment:
            print(f"Successfully commented")
        else:
            print(f"Failed to comment")
        # print(f"Now cleaning up..")
        # repo_manager.clean_up(repo_path)
        # print("Completed cleanup")
        return {
            "status": "success",
            "prn_number": pr_number,
            "files_changed": len(diff_data['diff_files']),
            "changed_files": diff_data['diff_files']
        }
    except Exception as e:
        print(f"ERROR in webhook: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
```

**Dependencies:** verify_signature
**Imports Used:** datetime, traceback, json

---

### Function Dependencies

- **github_webhook()** → **verify_signature()** (line 26)

### Imports Used

- **services.history_fetcher** (from import, line 8)
- **git_ops.repo_manager** (from import, line 5)
- **ai.code_reviewer** (from import, line 6)
- **services.enhanced_context_builder** (from import, line 9)
- **typing** (from import, line 3)
- **fastapi** (from import, line 1)
- **utils.github_bot** (from import, line 7)
- **utils.config** (from import, line 4)
- **hmac** (direct import, line 2)
- **datetime** (direct import, line 107)
- **traceback** (direct import, line 153)
- **hashlib** (direct import, line 2)
- **json** (direct import, line 2)




## AI Instructions

Please provide a comprehensive code review that considers:

1. **Code Quality**: Best practices, patterns, potential improvements
2. **Security**: Any security vulnerabilities or concerns
3. **Performance**: Performance implications and optimizations
4. **Dependencies**: Impact of new imports and function dependencies
5. **Maintainability**: Code readability and future maintenance
6. **Testing**: Testability and testing suggestions

Focus on the changed functions and their dependencies. Consider the PR history to avoid repeating previous suggestions.

---
*Context generated by enhanced AST parser + PR history analysis*
